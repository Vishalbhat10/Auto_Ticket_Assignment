{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "03 - Automated Ticket Assignment - Capstone Project - Approach2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6U1SeAnzllo"
      },
      "source": [
        "# Automatic Ticket Assignment - Capstone Project - Approach2\n",
        "\n",
        "## Problem Statement - \n",
        "\n",
        "In most of the IT organizations, the assignment of incidents to appropriate IT groups is still a manual process. Manual assignment of incidents is time consuming and requires human efforts. There may be mistakes due to human errors and resource consumption is carried out ineffectively because of the misaddressing. On the other hand, manual assignment increases the response and resolution times which result in user satisfaction deterioration / poor customer service. \n",
        "\n",
        "_<font color=blue>This capstone project intends to reduce the manual intervention of IT operations or Service desk teams by automating the ticket assignment process.The goal here is to create a text classification based ML model that can automatically  classify any new tickets by analysing ticket description to one of the relevant Assignment groups, which could be later integrated to any ITSM tool like Service Now. Based on the ticket description our model will output the probability of assigning it to one of the 74 Groups.</font>_\n",
        "\n",
        "The solution would be implemented using below approach:\n",
        "\n",
        "In the AS-IS process it's mentioned that around ~54% of the incidents are resolved by L1 / L2 teams and the rest will be resolved as L3. So the assumption is that GRP_0 and GRP_8 which contribute 54% of the tickets are related to L1/L2 teams and the rest of the tickets belongs to L3 teams\n",
        "\n",
        "So firstly, the ticket would be classified into L1/L2 or L3 classes and then it would be further classified into one of the given assignment groups. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGmGDXCSVx7h",
        "outputId": "46e86809-672e-43ea-b208-fc743fe696dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjcZjc23WYsi",
        "outputId": "2fe46ff7-7afe-4e1a-8449-f3ef154f1f79"
      },
      "source": [
        "cd drive/MyDrive/projects/AutoTicketAssignment/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/projects/AutoTicketAssignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xmQ-9Cfzllp"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zReBCzBUzllp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYpR2-ZLzllq"
      },
      "source": [
        "### Load the preprocessed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "GU2CLfyyzllq",
        "outputId": "879db459-f80f-4f50-f25c-1901f3eec91c"
      },
      "source": [
        "df_incidents_level = pd.read_csv('processed_file_modellling.csv',encoding='utf-8')\n",
        "df_incidents_level.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>cleaned_description</th>\n",
              "      <th>num_wds</th>\n",
              "      <th>avg_word</th>\n",
              "      <th>uniq_wds</th>\n",
              "      <th>token_desc</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>login issue verified user detailsemployee mana...</td>\n",
              "      <td>19</td>\n",
              "      <td>7.157895</td>\n",
              "      <td>16</td>\n",
              "      <td>login issue verified user detailsemployee mana...</td>\n",
              "      <td>L1/L2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>outlook hmjdrvpbkomuaywn teammy meetingsskype ...</td>\n",
              "      <td>13</td>\n",
              "      <td>7.538462</td>\n",
              "      <td>12</td>\n",
              "      <td>outlook hmjdrvpbkomuaywn teammy meetingsskype ...</td>\n",
              "      <td>L1/L2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>cant log vpn eylqgodmybqkwiami cannot log vpn</td>\n",
              "      <td>7</td>\n",
              "      <td>5.571429</td>\n",
              "      <td>5</td>\n",
              "      <td>cant log vpn eylqgodmybqkwiami cannot log vpn</td>\n",
              "      <td>L1/L2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable access hrtool page unable access hrtool...</td>\n",
              "      <td>8</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>4</td>\n",
              "      <td>unable access hrtool page unable access hrtool...</td>\n",
              "      <td>L1/L2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>skype error skype error</td>\n",
              "      <td>4</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>skype error skype error</td>\n",
              "      <td>L1/L2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Assignment group  ... Target\n",
              "0            GRP_0  ...  L1/L2\n",
              "1            GRP_0  ...  L1/L2\n",
              "2            GRP_0  ...  L1/L2\n",
              "3            GRP_0  ...  L1/L2\n",
              "4            GRP_0  ...  L1/L2\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemolymVzllv"
      },
      "source": [
        "Since the dataset is very imbalanced, we will be considering a subset of groups for predictions. In 74 groups, 46% of tickets belong to group 1 and 16 groups have more than 100 tickets and around 22 groups have more than 50 tickets, rest of the Assignment groups have very less ticket counts which might not add much value to the model prediction. If we conducted random sampling towards all the subcategories, then we would face a problem that we might miss all the tickets in some categories. Hence, we considered the groups that have more than 50 tickets in this appoach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5anmAUe9WuXs"
      },
      "source": [
        "df_incidents_level.rename(columns={'Assignment group': 'Assignment_group'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1akg62Kzllv"
      },
      "source": [
        "df_incidents_level = df_incidents_level[df_incidents_level['Assignment_group'].map(df_incidents_level['Assignment_group'].value_counts()) > 50]\n",
        "x = df_incidents_level['token_desc']\n",
        "y = df_incidents_level['Target']\n",
        "\n",
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "# encoding train labels \n",
        "encoder.fit(y)\n",
        "y = encoder.transform(y)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=13,stratify=y)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "class_weights\n",
        "\n",
        "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
        "for i, val in enumerate(y_train):\n",
        "    w_array[i] = class_weights[val]\n",
        "    \n",
        "    \n",
        "log_cols=[\"Classifier\", \"accuracy\",\"f1_score\"]\n",
        "log1 = pd.DataFrame(columns=log_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZQI3SnUzllv"
      },
      "source": [
        "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
        "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
        "    :param actual: Array containing the actual target classes\n",
        "    :param predicted: Matrix with class predictions, one probability per class\n",
        "    \"\"\"\n",
        "    # Convert 'actual' to a binary array if it's not already:\n",
        "    if len(actual.shape) == 1:\n",
        "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "        for i, val in enumerate(actual):\n",
        "            actual2[i, val] = 1\n",
        "        actual = actual2\n",
        "\n",
        "    clip = np.clip(predicted, eps, 1 - eps)\n",
        "    rows = actual.shape[0]\n",
        "    vsota = np.sum(actual * np.log(clip))\n",
        "    return -1.0 / rows * vsota"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx4-i6JTzllv"
      },
      "source": [
        "### Modeling\n",
        "\n",
        "Pass the data to various models which learns to classify the tickets into one of the two groups -  L1/L2 or L3 class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CygqdbSEzllv"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTs9aq2Vzllv",
        "outputId": "3cec3e3d-4f79-4e31-ca9a-b1eaf3ae59e6"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "predictions = nb.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test)) \n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "\n",
        "log_entry = pd.DataFrame([[\"MultinomialNB\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log1 = log1.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5618122977346278\n",
            "f1 score 0.6216366968921104\n",
            "logloss: 0.699 \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.87      0.69       850\n",
            "           1       0.54      0.19      0.28       695\n",
            "\n",
            "    accuracy                           0.56      1545\n",
            "   macro avg       0.55      0.53      0.48      1545\n",
            "weighted avg       0.55      0.56      0.50      1545\n",
            "\n",
            "[[738 112]\n",
            " [565 130]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK_efiKezllw"
      },
      "source": [
        "#### Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOGSD1apzllw",
        "outputId": "38ce8962-5432-49c5-f656-177626ac5486"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svc = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', OneVsRestClassifier(LinearSVC(loss='hinge',random_state=42,class_weight='balanced'))),\n",
        "               ])\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "log_entry = pd.DataFrame([[\"LinearSVC\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log1 = log1.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5300970873786408\n",
            "f1 score 0.5289222313696916\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.53      0.55       850\n",
            "           1       0.48      0.53      0.50       695\n",
            "\n",
            "    accuracy                           0.53      1545\n",
            "   macro avg       0.53      0.53      0.53      1545\n",
            "weighted avg       0.53      0.53      0.53      1545\n",
            "\n",
            "[[452 398]\n",
            " [328 367]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak8i1PbQzllw"
      },
      "source": [
        "#### SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn8Z10phzllw",
        "outputId": "fb7fe70c-e582-4e64-c7bc-10140a06363e"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None,class_weight='balanced')),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"SGDClassifier\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log1 = log1.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5339805825242718\n",
            "f1 score 0.5399247317814854\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.42      0.50       850\n",
            "           1       0.49      0.67      0.57       695\n",
            "\n",
            "    accuracy                           0.53      1545\n",
            "   macro avg       0.55      0.55      0.53      1545\n",
            "weighted avg       0.56      0.53      0.53      1545\n",
            "\n",
            "[[356 494]\n",
            " [226 469]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8DP6Qljzllw"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGmjSbG7zllw",
        "outputId": "2d3add66-6ba3-40b0-a785-3282dea557c1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg_1 = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5,class_weight='balanced')),\n",
        "               ])\n",
        "logreg_1.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg_1.predict(X_test)\n",
        "predictions = logreg_1.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"LogisticRegression\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log1 = log1.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5029126213592233\n",
            "f1 score 0.5017719754539705\n",
            "logloss: 3.156 \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.52      0.53       850\n",
            "           1       0.45      0.49      0.47       695\n",
            "\n",
            "    accuracy                           0.50      1545\n",
            "   macro avg       0.50      0.50      0.50      1545\n",
            "weighted avg       0.51      0.50      0.50      1545\n",
            "\n",
            "[[439 411]\n",
            " [357 338]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ET3t7nptzllw",
        "outputId": "5f6fa62c-48b1-468f-8dc3-e4ba7754a771"
      },
      "source": [
        "log1.set_index([\"Classifier\"],inplace=True)\n",
        "log1.sort_values(by=['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.502913</td>\n",
              "      <td>0.501772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.530097</td>\n",
              "      <td>0.528922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.533981</td>\n",
              "      <td>0.539925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.561812</td>\n",
              "      <td>0.621637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  f1_score\n",
              "Classifier                            \n",
              "LogisticRegression  0.502913  0.501772\n",
              "LinearSVC           0.530097  0.528922\n",
              "SGDClassifier       0.533981  0.539925\n",
              "MultinomialNB       0.561812  0.621637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "nUQYPirrzll0",
        "outputId": "2294cbc5-e11e-47d5-e49a-e87d0af93edc"
      },
      "source": [
        "log1.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fc1f675f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToULmwSGzll1"
      },
      "source": [
        "Linear SVC gives better performance compared to other models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zILpQU6tzll1",
        "outputId": "2608671e-d1da-4acd-ccf4-347a9dadae1c"
      },
      "source": [
        "### Save the model\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(svc, 'l1_l2_classification.pkl', compress=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['l1_l2_classification.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVx61xZTzll1",
        "outputId": "05e65306-4457-4492-8343-f02dd52039c8"
      },
      "source": [
        "le_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "le_name_mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'L1/L2': 0, 'L3': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBsHp2_Lzll2",
        "outputId": "25182c9c-1cb4-4562-c808-9c783b90dd08"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "model = joblib.load('l1_l2_classification.pkl')\n",
        "\n",
        "sentence = 'job failed in scheduler'\n",
        "encoder.inverse_transform(model.predict([sentence]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['L3'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzdFBgj4zll2"
      },
      "source": [
        "## Model1 - Classification of L1/L2 tickets between GRP0 and GRP8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g2xTsmtzll2",
        "outputId": "5d764986-ee60-451a-fb9a-7c56a657819f"
      },
      "source": [
        "df_incidents_l1_l2 = df_incidents_level[df_incidents_level['Target'] == 'L1/L2']\n",
        "df_incidents_l1_l2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4248, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuWzruhIzll2",
        "outputId": "2021cf6a-a731-49e5-83dc-0dcd0698faec"
      },
      "source": [
        "df_incidents_l1_l2.Assignment_group.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRP_0     2437\n",
              "GRP_8      374\n",
              "GRP_24     144\n",
              "GRP_12     134\n",
              "GRP_9      115\n",
              "GRP_2      100\n",
              "GRP_19      99\n",
              "GRP_3       89\n",
              "GRP_6       84\n",
              "GRP_13      74\n",
              "GRP_10      65\n",
              "GRP_14      64\n",
              "GRP_25      54\n",
              "GRP_4       50\n",
              "GRP_5       47\n",
              "GRP_33      46\n",
              "GRP_17      42\n",
              "GRP_29      41\n",
              "GRP_16      39\n",
              "GRP_7       37\n",
              "GRP_18      31\n",
              "GRP_34      29\n",
              "GRP_26      27\n",
              "GRP_31      26\n",
              "Name: Assignment_group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1An-AoKmzll2"
      },
      "source": [
        "x = df_incidents_l1_l2['token_desc']\n",
        "y = df_incidents_l1_l2['Assignment_group']\n",
        "\n",
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "# encoding train labels \n",
        "encoder.fit(y)\n",
        "y = encoder.transform(y)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=13,stratify=y)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "class_weights\n",
        "\n",
        "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
        "for i, val in enumerate(y_train):\n",
        "    w_array[i] = class_weights[val]\n",
        "    \n",
        "    \n",
        "log_cols=[\"Classifier\", \"accuracy\",\"f1_score\"]\n",
        "log2 = pd.DataFrame(columns=log_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFH85mLozll2"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWAnJFMEzll2",
        "outputId": "0a0b86a0-89e8-4a5e-bd15-671829649593"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "predictions = nb.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test)) \n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "\n",
        "log_entry = pd.DataFrame([[\"MultinomialNB\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log2 = log2.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6647058823529411\n",
            "f1 score 0.7888738326389686\n",
            "logloss: 1.591 \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80       488\n",
            "           1       0.00      0.00      0.00        13\n",
            "           2       0.80      0.15      0.25        27\n",
            "           3       0.00      0.00      0.00        15\n",
            "           4       0.00      0.00      0.00        13\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.00      0.00      0.00         8\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00        20\n",
            "           9       0.00      0.00      0.00        20\n",
            "          10       1.00      0.10      0.19        29\n",
            "          11       0.00      0.00      0.00        11\n",
            "          12       0.00      0.00      0.00         5\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.00      0.00      0.00        18\n",
            "          15       0.00      0.00      0.00         5\n",
            "          16       0.00      0.00      0.00         9\n",
            "          17       0.00      0.00      0.00         6\n",
            "          18       0.00      0.00      0.00        10\n",
            "          19       0.00      0.00      0.00         9\n",
            "          20       0.00      0.00      0.00        17\n",
            "          21       0.00      0.00      0.00         7\n",
            "          22       0.61      0.93      0.74        75\n",
            "          23       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.66       850\n",
            "   macro avg       0.13      0.09      0.08       850\n",
            "weighted avg       0.50      0.66      0.54       850\n",
            "\n",
            "[[488   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   3   0]\n",
            " [ 21   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   2   0]\n",
            " [ 15   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 26   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 11   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   1   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   6   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  13   0]\n",
            " [  7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  4   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  70   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  20   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm0W2HQyzll3"
      },
      "source": [
        "### Linear Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM8pfztOzll3",
        "outputId": "be09d8d9-e5dc-4c67-ffd6-a0961cfac0e4"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "svc = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', OneVsRestClassifier(LinearSVC(loss='hinge',random_state=42,class_weight='balanced'))),\n",
        "               ])\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "print('Test accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('Test f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"LinearSVC\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log2 = log2.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 0.6858823529411765\n",
            "Test f1 score 0.6848344421994538\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       488\n",
            "           1       0.50      0.23      0.32        13\n",
            "           2       0.50      0.70      0.58        27\n",
            "           3       0.59      0.67      0.62        15\n",
            "           4       0.44      0.31      0.36        13\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.89      1.00      0.94         8\n",
            "           7       0.67      0.33      0.44         6\n",
            "           8       0.28      0.25      0.26        20\n",
            "           9       0.53      0.40      0.46        20\n",
            "          10       0.83      0.83      0.83        29\n",
            "          11       0.50      0.27      0.35        11\n",
            "          12       0.00      0.00      0.00         5\n",
            "          13       0.62      0.62      0.62         8\n",
            "          14       0.29      0.39      0.33        18\n",
            "          15       0.50      0.40      0.44         5\n",
            "          16       0.43      0.33      0.38         9\n",
            "          17       0.33      0.17      0.22         6\n",
            "          18       0.67      0.20      0.31        10\n",
            "          19       0.08      0.78      0.14         9\n",
            "          20       0.60      0.18      0.27        17\n",
            "          21       0.75      0.86      0.80         7\n",
            "          22       0.83      0.33      0.48        75\n",
            "          23       0.38      0.13      0.19        23\n",
            "\n",
            "    accuracy                           0.69       850\n",
            "   macro avg       0.50      0.43      0.43       850\n",
            "weighted avg       0.73      0.69      0.69       850\n",
            "\n",
            "[[433   1   8   1   2   1   1   0   8   5   3   1   1   0  10   2   2   2\n",
            "    1   0   0   2   2   2]\n",
            " [  4   3   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2   0   0   0   1]\n",
            " [  5   0  19   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
            "    0   1   0   0   1   0]\n",
            " [  1   0   0  10   0   0   0   0   0   1   0   1   0   1   0   0   0   0\n",
            "    0   0   1   0   0   0]\n",
            " [  6   0   3   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  6   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   1   0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0   1   0   0   0]\n",
            " [  9   0   1   0   0   0   0   0   5   1   0   0   0   0   4   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  9   0   1   0   1   0   0   0   0   8   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1]\n",
            " [  0   0   1   0   0   0   0   0   0   0  24   1   0   0   1   0   2   0\n",
            "    0   0   0   0   0   0]\n",
            " [  4   0   0   0   1   0   0   0   1   0   0   3   0   0   1   0   0   0\n",
            "    0   0   0   0   0   1]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   1   0   0   0   0   0   0   0   5   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  6   0   0   0   0   0   0   0   4   0   0   0   0   0   7   0   0   0\n",
            "    0   0   0   0   1   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   1   2   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   3   0\n",
            "    0   1   0   0   0   0]\n",
            " [  2   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
            "    0   0   0   0   0   0]\n",
            " [  7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    2   0   0   0   1   0]\n",
            " [  0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   7   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0  13   3   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   6   0   0]\n",
            " [  1   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0  47   0   0  25   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0  19   0   0   0   3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVLhf-gyzll3"
      },
      "source": [
        "### SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vohWi9hjzll3",
        "outputId": "5fa8a084-d93e-4596-a81f-22d23055e09f"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None,class_weight='balanced')),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "\n",
        "log_entry = pd.DataFrame([[\"SGDClassifier\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log2 = log2.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5411764705882353\n",
            "f1 score 0.49356516447305127\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.62      0.74       488\n",
            "           1       0.08      0.54      0.13        13\n",
            "           2       0.41      0.48      0.44        27\n",
            "           3       0.45      0.67      0.54        15\n",
            "           4       0.47      0.69      0.56        13\n",
            "           5       0.17      0.62      0.26         8\n",
            "           6       0.57      1.00      0.73         8\n",
            "           7       0.18      0.50      0.26         6\n",
            "           8       0.31      0.25      0.28        20\n",
            "           9       0.33      0.45      0.38        20\n",
            "          10       0.67      0.76      0.71        29\n",
            "          11       0.26      0.64      0.37        11\n",
            "          12       0.13      0.40      0.20         5\n",
            "          13       0.32      0.75      0.44         8\n",
            "          14       0.25      0.39      0.30        18\n",
            "          15       0.16      0.60      0.25         5\n",
            "          16       0.33      0.67      0.44         9\n",
            "          17       0.04      0.17      0.07         6\n",
            "          18       0.26      0.50      0.34        10\n",
            "          19       0.50      0.11      0.18         9\n",
            "          20       0.08      0.06      0.07        17\n",
            "          21       0.40      0.86      0.55         7\n",
            "          22       0.88      0.28      0.42        75\n",
            "          23       0.50      0.09      0.15        23\n",
            "\n",
            "    accuracy                           0.54       850\n",
            "   macro avg       0.36      0.50      0.37       850\n",
            "weighted avg       0.73      0.54      0.59       850\n",
            "\n",
            "[[301   8  11   2   4  17   6   7   9  12   8  13  10   5  14  13   9  18\n",
            "   11   0   1   5   2   2]\n",
            " [  1   7   0   4   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  2   2  13   1   2   1   0   0   0   1   0   0   0   0   0   2   0   2\n",
            "    0   0   0   0   1   0]\n",
            " [  0   0   0  10   0   0   0   1   0   1   0   1   0   2   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  1   0   1   0   9   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0]\n",
            " [  1   0   0   2   0   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   1   0   1   0   0   0   3   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  2   1   2   0   0   1   0   1   5   1   1   0   0   2   3   0   0   0\n",
            "    0   0   0   1   0   0]\n",
            " [  4   0   0   0   1   0   0   0   0   9   0   0   1   1   0   1   0   2\n",
            "    1   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0  22   3   0   0   1   0   2   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   1   1   1   0   0   0   0   0   7   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   1   0\n",
            "    0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   1   0   0   0   0   0   0   0   6   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   1   2   1   0   1   2   0   7   0   0   1\n",
            "    0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   3   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   1   0   0   0   0   1   0   0   0   0   0   6   0\n",
            "    0   0   0   0   0   0]\n",
            " [  1   0   2   0   0   1   0   0   0   1   0   0   0   0   0   0   0   1\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   1   0   0   1   0   0   0\n",
            "    5   0   0   2   0   0]\n",
            " [  0   5   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   1   1   0   0   0]\n",
            " [  0  12   0   0   0   0   0   2   0   0   0   0   0   1   0   0   0   0\n",
            "    0   1   1   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   6   0   0]\n",
            " [  0  39   2   0   1   1   0   0   0   0   0   0   0   0   1   0   0   0\n",
            "    2   0   8   0  21   0]\n",
            " [  0  17   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   2   0   0   2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU-Sq9-Bzll3"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnXy9mx-zll3",
        "outputId": "c36b2f16-dcb6-41a8-88df-4ea810b3061e"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg_1 = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5,class_weight='balanced')),\n",
        "               ])\n",
        "logreg_1.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg_1.predict(X_test)\n",
        "predictions = logreg_1.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"LogisticRegression\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log2 = log2.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6929411764705883\n",
            "f1 score 0.7023237025586234\n",
            "logloss: 1.597 \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84       488\n",
            "           1       0.67      0.31      0.42        13\n",
            "           2       0.44      0.74      0.56        27\n",
            "           3       0.77      0.67      0.71        15\n",
            "           4       0.55      0.46      0.50        13\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.88      0.88      0.88         8\n",
            "           7       0.60      0.50      0.55         6\n",
            "           8       0.33      0.35      0.34        20\n",
            "           9       0.36      0.40      0.38        20\n",
            "          10       0.82      0.79      0.81        29\n",
            "          11       0.75      0.27      0.40        11\n",
            "          12       0.00      0.00      0.00         5\n",
            "          13       0.33      0.12      0.18         8\n",
            "          14       0.35      0.33      0.34        18\n",
            "          15       0.25      0.40      0.31         5\n",
            "          16       0.38      0.33      0.35         9\n",
            "          17       0.00      0.00      0.00         6\n",
            "          18       0.67      0.20      0.31        10\n",
            "          19       0.15      0.22      0.18         9\n",
            "          20       0.60      0.18      0.27        17\n",
            "          21       0.80      0.57      0.67         7\n",
            "          22       0.58      0.79      0.67        75\n",
            "          23       0.50      0.17      0.26        23\n",
            "\n",
            "    accuracy                           0.69       850\n",
            "   macro avg       0.48      0.40      0.41       850\n",
            "weighted avg       0.70      0.69      0.68       850\n",
            "\n",
            "[[412   0  11   1   2   3   1   0   9  12   3   0   1   0   6   5   3  14\n",
            "    0   0   0   1   2   2]\n",
            " [  5   4   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   2   1]\n",
            " [  4   0  20   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
            "    0   0   0   0   2   0]\n",
            " [  1   0   0  10   0   0   0   2   0   1   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  5   0   2   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   7   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  1   1   0   1   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  9   0   1   0   0   0   0   0   7   1   0   0   0   0   2   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [ 10   0   1   0   1   0   0   0   0   8   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  2   0   1   0   0   0   0   0   0   0  23   1   0   0   0   0   2   0\n",
            "    0   0   0   0   0   0]\n",
            " [  4   0   0   0   1   0   0   0   1   0   0   3   0   0   1   0   0   0\n",
            "    0   0   0   0   0   1]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0   2   0   0   0]\n",
            " [  6   0   1   0   0   0   0   0   4   0   0   0   0   0   6   0   0   0\n",
            "    0   0   0   0   1   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   1   2   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   3   0\n",
            "    0   0   0   0   0   0]\n",
            " [  3   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    2   0   0   0   1   0]\n",
            " [  0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2   0   0   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0   1   3   0  12   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0   0\n",
            "    0   0   0   4   0   0]\n",
            " [  1   0   4   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    1   8   0   0  59   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2   0   0  17   4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6vLQGf9mzll3",
        "outputId": "0be1d74a-8604-45f7-ea61-55ef2dd99354"
      },
      "source": [
        "log2.set_index([\"Classifier\"],inplace=True)\n",
        "log2.sort_values(by=['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.541176</td>\n",
              "      <td>0.493565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.685882</td>\n",
              "      <td>0.684834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.692941</td>\n",
              "      <td>0.702324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.664706</td>\n",
              "      <td>0.788874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  f1_score\n",
              "Classifier                            \n",
              "SGDClassifier       0.541176  0.493565\n",
              "LinearSVC           0.685882  0.684834\n",
              "LogisticRegression  0.692941  0.702324\n",
              "MultinomialNB       0.664706  0.788874"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "2Rw_N0MOzll3",
        "outputId": "bf93b6a7-bb69-4faa-ac59-f4c07f6b33a7"
      },
      "source": [
        "log2.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fbebe29b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_EeNas1zll4",
        "outputId": "b7855eaf-3985-4da9-ba21-0ddf1465c330"
      },
      "source": [
        "\n",
        "### Save the model\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(logreg_1, 'model_l1_l2.pkl', compress=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_l1_l2.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yhnqXy7zll4",
        "outputId": "6c9d1193-a94c-4434-bc84-be70b1aca6c8"
      },
      "source": [
        "le_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "le_name_mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GRP_0': 0,\n",
              " 'GRP_10': 1,\n",
              " 'GRP_12': 2,\n",
              " 'GRP_13': 3,\n",
              " 'GRP_14': 4,\n",
              " 'GRP_16': 5,\n",
              " 'GRP_17': 6,\n",
              " 'GRP_18': 7,\n",
              " 'GRP_19': 8,\n",
              " 'GRP_2': 9,\n",
              " 'GRP_24': 10,\n",
              " 'GRP_25': 11,\n",
              " 'GRP_26': 12,\n",
              " 'GRP_29': 13,\n",
              " 'GRP_3': 14,\n",
              " 'GRP_31': 15,\n",
              " 'GRP_33': 16,\n",
              " 'GRP_34': 17,\n",
              " 'GRP_4': 18,\n",
              " 'GRP_5': 19,\n",
              " 'GRP_6': 20,\n",
              " 'GRP_7': 21,\n",
              " 'GRP_8': 22,\n",
              " 'GRP_9': 23}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB0pRl1Vzll4",
        "outputId": "3ba13ab8-a05f-4085-ae4f-36512cb6d99b"
      },
      "source": [
        "\n",
        "from sklearn.externals import joblib\n",
        "model = joblib.load('model_l1_l2.pkl')\n",
        "\n",
        "sentence = 'job failed in scheduler'\n",
        "encoder.inverse_transform(model.predict([sentence]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['GRP_5'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRCedFk0zll4"
      },
      "source": [
        "## Model to classify L3 tickets\n",
        "\n",
        "Lets's now train the models to classify the L3 tickets into one of the assignement groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6TxNEcbzll4"
      },
      "source": [
        "df_incidents_l3 = df_incidents_level[df_incidents_level['Target'] == 'L3']\n",
        "df_incidents_l3 = df_incidents_l3[df_incidents_l3['Assignment_group'].map(df_incidents_l3['Assignment_group'].value_counts()) > 50]\n",
        "x = df_incidents_l3['token_desc']\n",
        "y = df_incidents_l3['Assignment_group']\n",
        "\n",
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "# encoding train labels \n",
        "encoder.fit(y)\n",
        "y = encoder.transform(y)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=13,stratify=y)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "class_weights\n",
        "\n",
        "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
        "for i, val in enumerate(y_train):\n",
        "    w_array[i] = class_weights[val]\n",
        "    \n",
        "log_cols=[\"Classifier\", \"accuracy\",\"f1_score\"]\n",
        "log = pd.DataFrame(columns=log_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdGE6yhBzll4"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyq4jPy4zll4",
        "outputId": "7e5b188d-397e-4cf0-b9de-0656eb66ef8a"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "predictions = nb.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test)) \n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"MultinomialNB\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log = log.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5816485225505443\n",
            "f1 score 0.7132671735077503\n",
            "logloss: 1.526 \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      1.00      0.74       308\n",
            "           1       0.00      0.00      0.00        15\n",
            "           2       1.00      0.20      0.33        25\n",
            "           3       0.00      0.00      0.00        14\n",
            "           4       0.00      0.00      0.00        11\n",
            "           5       0.00      0.00      0.00        11\n",
            "           6       0.00      0.00      0.00        23\n",
            "           7       0.67      0.07      0.13        28\n",
            "           8       1.00      0.28      0.43        29\n",
            "           9       0.00      0.00      0.00        12\n",
            "          10       0.00      0.00      0.00        11\n",
            "          11       0.00      0.00      0.00        22\n",
            "          12       0.00      0.00      0.00        12\n",
            "          13       0.00      0.00      0.00        16\n",
            "          14       0.00      0.00      0.00        20\n",
            "          15       0.49      0.88      0.63        58\n",
            "          16       0.00      0.00      0.00        28\n",
            "\n",
            "    accuracy                           0.58       643\n",
            "   macro avg       0.22      0.14      0.13       643\n",
            "weighted avg       0.44      0.58      0.45       643\n",
            "\n",
            "[[308   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0]\n",
            " [ 20   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 11   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 11   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 26   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0]\n",
            " [ 21   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0]\n",
            " [ 12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0]\n",
            " [ 21   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0]\n",
            " [ 12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   0]\n",
            " [  7   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51   0]\n",
            " [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSi-F_kvzll5"
      },
      "source": [
        "### Linear Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCUAv-h7zll5",
        "outputId": "6f4e39dd-b26b-4ace-9702-064ced89fa78"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "svc = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', OneVsRestClassifier(LinearSVC(loss='hinge',random_state=42,class_weight='balanced'))),\n",
        "               ])\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "print('Test accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('Test f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"LinearSVC\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log = log.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 0.6671850699844479\n",
            "Test f1 score 0.669417117147617\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       308\n",
            "           1       0.50      0.33      0.40        15\n",
            "           2       0.70      0.76      0.73        25\n",
            "           3       0.90      0.64      0.75        14\n",
            "           4       0.33      0.18      0.24        11\n",
            "           5       0.78      0.64      0.70        11\n",
            "           6       0.25      0.30      0.27        23\n",
            "           7       0.41      0.43      0.42        28\n",
            "           8       0.84      0.90      0.87        29\n",
            "           9       0.67      0.67      0.67        12\n",
            "          10       0.60      0.55      0.57        11\n",
            "          11       0.38      0.23      0.29        22\n",
            "          12       0.64      0.58      0.61        12\n",
            "          13       0.33      0.06      0.11        16\n",
            "          14       0.20      0.90      0.33        20\n",
            "          15       0.95      0.34      0.51        58\n",
            "          16       0.73      0.29      0.41        28\n",
            "\n",
            "    accuracy                           0.67       643\n",
            "   macro avg       0.59      0.51      0.51       643\n",
            "weighted avg       0.72      0.67      0.66       643\n",
            "\n",
            "[[269   0   3   0   1   0  12  13   2   1   1   4   1   0   1   0   0]\n",
            " [  0   5   0   0   0   0   0   0   0   1   0   0   0   0   9   0   0]\n",
            " [  2   0  19   0   0   0   1   0   2   0   0   0   1   0   0   0   0]\n",
            " [  1   2   0   9   0   1   0   0   0   0   1   0   0   0   0   0   0]\n",
            " [  3   0   3   0   2   0   0   0   0   0   0   0   0   0   0   1   2]\n",
            " [  3   0   0   0   0   7   0   0   0   0   0   0   0   0   1   0   0]\n",
            " [ 14   0   0   0   0   0   7   0   0   1   0   1   0   0   0   0   0]\n",
            " [ 12   0   1   0   0   0   1  12   0   1   1   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0  26   0   0   1   1   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   8   0   0   1   0   0   0   0]\n",
            " [  2   2   0   0   0   0   0   0   0   0   6   0   0   0   1   0   0]\n",
            " [  7   0   0   0   0   0   7   3   0   0   0   5   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   1   0   0   1   7   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   1   0   1  13   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   1   0   0   0  18   0   0]\n",
            " [  1   0   1   0   2   0   0   0   0   0   0   0   0   2  31  20   1]\n",
            " [  2   1   0   1   1   1   0   0   0   0   0   0   0   0  14   0   8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgpOMGL5zll5"
      },
      "source": [
        "### SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WrPpc-Wzll5",
        "outputId": "bbf3f5b1-f8a6-4f3b-faf7-960d738415b8"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None,class_weight='balanced')),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"SGDClassifier\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log = log.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6236391912908242\n",
            "f1 score 0.6191631913481135\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.71      0.80       308\n",
            "           1       0.14      0.20      0.16        15\n",
            "           2       0.58      0.76      0.66        25\n",
            "           3       0.47      0.64      0.55        14\n",
            "           4       0.20      0.18      0.19        11\n",
            "           5       0.31      0.73      0.43        11\n",
            "           6       0.33      0.43      0.38        23\n",
            "           7       0.41      0.46      0.43        28\n",
            "           8       0.62      0.86      0.72        29\n",
            "           9       0.52      1.00      0.69        12\n",
            "          10       0.33      0.55      0.41        11\n",
            "          11       0.33      0.27      0.30        22\n",
            "          12       0.41      0.75      0.53        12\n",
            "          13       0.33      0.06      0.11        16\n",
            "          14       0.80      0.40      0.53        20\n",
            "          15       0.51      0.79      0.62        58\n",
            "          16       0.62      0.18      0.28        28\n",
            "\n",
            "    accuracy                           0.62       643\n",
            "   macro avg       0.46      0.53      0.46       643\n",
            "weighted avg       0.68      0.62      0.63       643\n",
            "\n",
            "[[219   5   7   3   4  10  13  14   4   5   4   8  10   0   1   0   1]\n",
            " [  0   3   0   2   0   0   0   0   0   1   0   0   0   0   0   9   0]\n",
            " [  0   0  19   0   0   0   1   0   3   1   0   0   1   0   0   0   0]\n",
            " [  0   1   0   9   0   1   0   0   0   0   3   0   0   0   0   0   0]\n",
            " [  2   0   3   0   2   0   0   0   0   0   0   0   0   0   0   2   2]\n",
            " [  1   0   0   0   0   8   0   0   0   0   1   1   0   0   0   0   0]\n",
            " [  6   0   0   1   0   0  10   3   1   1   0   0   1   0   0   0   0]\n",
            " [  6   0   1   1   1   0   1  13   0   1   2   1   0   0   1   0   0]\n",
            " [  1   0   0   0   0   0   0   0  25   1   0   1   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0]\n",
            " [  0   2   0   1   0   0   0   0   1   0   6   0   0   0   0   1   0]\n",
            " [  2   0   0   0   1   1   5   2   3   0   2   6   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   3   0   0   0   9   0   0   0   0]\n",
            " [  0   1   0   0   0   1   0   0   0   0   0   1   0   1   0  12   0]\n",
            " [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   8   9   0]\n",
            " [  1   5   1   0   2   1   0   0   0   0   0   0   0   2   0  46   0]\n",
            " [  0   3   2   2   0   3   0   0   0   1   0   0   0   0   0  12   5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw02nOXUzll5"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkCop8QGzll5",
        "outputId": "edac359a-8ea0-4f4b-b43f-062eb46d74e5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg_1 = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5,class_weight='balanced')),\n",
        "               ])\n",
        "logreg_1.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg_1.predict(X_test)\n",
        "predictions = logreg_1.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"LogisticRegression\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
        "log = log.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6594090202177294\n",
            "f1 score 0.6593670411339798\n",
            "logloss: 1.675 \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       308\n",
            "           1       0.50      0.20      0.29        15\n",
            "           2       0.67      0.56      0.61        25\n",
            "           3       0.75      0.64      0.69        14\n",
            "           4       0.60      0.27      0.37        11\n",
            "           5       0.83      0.45      0.59        11\n",
            "           6       0.26      0.30      0.28        23\n",
            "           7       0.46      0.43      0.44        28\n",
            "           8       0.76      0.90      0.83        29\n",
            "           9       0.89      0.67      0.76        12\n",
            "          10       0.62      0.45      0.53        11\n",
            "          11       0.53      0.41      0.46        22\n",
            "          12       0.57      0.67      0.62        12\n",
            "          13       0.19      0.88      0.31        16\n",
            "          14       0.47      0.45      0.46        20\n",
            "          15       0.95      0.36      0.53        58\n",
            "          16       0.73      0.29      0.41        28\n",
            "\n",
            "    accuracy                           0.66       643\n",
            "   macro avg       0.62      0.52      0.53       643\n",
            "weighted avg       0.71      0.66      0.66       643\n",
            "\n",
            "[[263   0   3   1   1   0  16  10   3   0   0   6   3   0   1   1   0]\n",
            " [  2   3   0   1   0   0   0   0   0   0   0   0   0   9   0   0   0]\n",
            " [  4   0  14   0   0   0   1   1   3   1   0   0   1   0   0   0   0]\n",
            " [  2   2   0   9   0   0   0   0   0   0   1   0   0   0   0   0   0]\n",
            " [  3   0   3   0   3   0   0   0   0   0   0   0   0   0   0   0   2]\n",
            " [  4   0   0   1   0   5   0   0   0   0   0   0   0   0   1   0   0]\n",
            " [ 14   0   0   0   0   0   7   0   0   0   0   2   0   0   0   0   0]\n",
            " [ 14   0   0   0   0   0   1  12   0   0   1   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0  26   0   0   0   1   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   8   0   0   1   0   0   0   0]\n",
            " [  4   1   0   0   0   0   0   0   0   0   5   0   0   1   0   0   0]\n",
            " [  9   0   0   0   0   0   2   2   0   0   0   9   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   2   0   0   0   8   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0  14   1   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   1   0   0   9   9   0   0]\n",
            " [  1   0   1   0   1   0   0   0   0   0   0   0   0  28   5  21   1]\n",
            " [  5   0   0   0   0   1   0   0   0   0   0   0   0  12   2   0   8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UO9h8iHRzll5",
        "outputId": "432f70fd-d57d-4d4d-a6d7-366a3ab1af7a"
      },
      "source": [
        "log.set_index([\"Classifier\"],inplace=True)\n",
        "log.sort_values(by=['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.623639</td>\n",
              "      <td>0.619163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.659409</td>\n",
              "      <td>0.659367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.667185</td>\n",
              "      <td>0.669417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.581649</td>\n",
              "      <td>0.713267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  f1_score\n",
              "Classifier                            \n",
              "SGDClassifier       0.623639  0.619163\n",
              "LogisticRegression  0.659409  0.659367\n",
              "LinearSVC           0.667185  0.669417\n",
              "MultinomialNB       0.581649  0.713267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "4m8nOQSHzll5",
        "outputId": "ade4dd34-fc16-4510-92b3-86a47159d2ea"
      },
      "source": [
        "log.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fc20ee630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD9jkE8tzll6"
      },
      "source": [
        "## Hyperparameter Tune GridSearchCV \n",
        "\n",
        "Let's tune each of the models using GridsearchCV to identify the best parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEeBAnotzll6"
      },
      "source": [
        "### Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjDb756dzll6",
        "outputId": "d72f6d12-776d-4894-bf96-738cfad4a72c"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\"clf__estimator__C\": [0.1, 1, 10, 100, 1000],  \n",
        "              'clf__estimator__loss': ['hinge','squared_hinge'],}  \n",
        "  \n",
        "clf_svc = GridSearchCV(svc, param_grid=params, refit = True, verbose = 1,scoring='f1_weighted') \n",
        "# fitting the model for grid search \n",
        "clf_svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Score: \", clf_svc.best_score_)\n",
        "print(\"Best Params: \", clf_svc.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   24.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.6676060726042718\n",
            "Best Params:  {'clf__estimator__C': 1, 'clf__estimator__loss': 'hinge'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xui4KHobzll6",
        "outputId": "eeae768b-4950-465e-8305-e97c44bcbf27"
      },
      "source": [
        "y_pred = clf_svc.best_estimator_.predict(X_test)\n",
        "#predictions = clf_svc.best_estimator_.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "#print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"LinearSVC_best_estimator\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols,index=['LinearSVC_best_estimator'])\n",
        "log = log.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6671850699844479\n",
            "f1 score 0.669417117147617\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       308\n",
            "           1       0.50      0.33      0.40        15\n",
            "           2       0.70      0.76      0.73        25\n",
            "           3       0.90      0.64      0.75        14\n",
            "           4       0.33      0.18      0.24        11\n",
            "           5       0.78      0.64      0.70        11\n",
            "           6       0.25      0.30      0.27        23\n",
            "           7       0.41      0.43      0.42        28\n",
            "           8       0.84      0.90      0.87        29\n",
            "           9       0.67      0.67      0.67        12\n",
            "          10       0.60      0.55      0.57        11\n",
            "          11       0.38      0.23      0.29        22\n",
            "          12       0.64      0.58      0.61        12\n",
            "          13       0.33      0.06      0.11        16\n",
            "          14       0.20      0.90      0.33        20\n",
            "          15       0.95      0.34      0.51        58\n",
            "          16       0.73      0.29      0.41        28\n",
            "\n",
            "    accuracy                           0.67       643\n",
            "   macro avg       0.59      0.51      0.51       643\n",
            "weighted avg       0.72      0.67      0.66       643\n",
            "\n",
            "[[269   0   3   0   1   0  12  13   2   1   1   4   1   0   1   0   0]\n",
            " [  0   5   0   0   0   0   0   0   0   1   0   0   0   0   9   0   0]\n",
            " [  2   0  19   0   0   0   1   0   2   0   0   0   1   0   0   0   0]\n",
            " [  1   2   0   9   0   1   0   0   0   0   1   0   0   0   0   0   0]\n",
            " [  3   0   3   0   2   0   0   0   0   0   0   0   0   0   0   1   2]\n",
            " [  3   0   0   0   0   7   0   0   0   0   0   0   0   0   1   0   0]\n",
            " [ 14   0   0   0   0   0   7   0   0   1   0   1   0   0   0   0   0]\n",
            " [ 12   0   1   0   0   0   1  12   0   1   1   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0  26   0   0   1   1   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   8   0   0   1   0   0   0   0]\n",
            " [  2   2   0   0   0   0   0   0   0   0   6   0   0   0   1   0   0]\n",
            " [  7   0   0   0   0   0   7   3   0   0   0   5   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   1   0   0   1   7   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   1   0   1  13   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   1   0   0   0  18   0   0]\n",
            " [  1   0   1   0   2   0   0   0   0   0   0   0   0   2  31  20   1]\n",
            " [  2   1   0   1   1   1   0   0   0   0   0   0   0   0  14   0   8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nrVkd47zll6"
      },
      "source": [
        "### SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVyIa1T4zll6",
        "outputId": "21c5e913-0883-4f12-a71e-2e1dbccbdf42"
      },
      "source": [
        "\n",
        "params = {\n",
        "    \"clf__loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
        "    \"clf__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
        "    \"clf__penalty\" : [\"l2\", \"l1\", \"none\"],\n",
        "}\n",
        "\n",
        "clf_sgd = GridSearchCV(sgd, param_grid=params,refit = True, verbose = 1,scoring='f1_weighted')\n",
        "clf_sgd.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Score: \", clf_sgd.best_score_)\n",
        "print(\"Best Params: \", clf_sgd.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  1.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.6636979641698132\n",
            "Best Params:  {'clf__alpha': 0.0001, 'clf__loss': 'log', 'clf__penalty': 'l2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFlBGONvzll6",
        "outputId": "7844fbe1-2868-469c-be69-9fbb40f2a8a0"
      },
      "source": [
        "y_pred = clf_sgd.best_estimator_.predict(X_test)\n",
        "#predictions = clf_svc.best_estimator_.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "#print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"SGD_best_estimator\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols,index=['SGD_best_estimator'])\n",
        "log = log.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6547433903576982\n",
            "f1 score 0.6546864611127663\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84       308\n",
            "           1       0.57      0.27      0.36        15\n",
            "           2       0.67      0.64      0.65        25\n",
            "           3       0.69      0.64      0.67        14\n",
            "           4       0.33      0.18      0.24        11\n",
            "           5       0.64      0.64      0.64        11\n",
            "           6       0.29      0.35      0.31        23\n",
            "           7       0.40      0.50      0.44        28\n",
            "           8       0.74      0.90      0.81        29\n",
            "           9       0.62      0.83      0.71        12\n",
            "          10       0.50      0.55      0.52        11\n",
            "          11       0.29      0.23      0.26        22\n",
            "          12       0.56      0.75      0.64        12\n",
            "          13       0.33      0.06      0.11        16\n",
            "          14       0.50      0.45      0.47        20\n",
            "          15       1.00      0.36      0.53        58\n",
            "          16       0.24      0.68      0.36        28\n",
            "\n",
            "    accuracy                           0.65       643\n",
            "   macro avg       0.54      0.52      0.50       643\n",
            "weighted avg       0.70      0.65      0.65       643\n",
            "\n",
            "[[255   1   3   1   1   1  12  16   3   1   1   7   5   0   1   0   0]\n",
            " [  1   4   0   1   0   0   0   0   0   0   0   0   0   0   0   0   9]\n",
            " [  2   0  16   0   0   0   1   1   3   1   0   0   1   0   0   0   0]\n",
            " [  1   1   0   9   0   1   0   0   0   0   2   0   0   0   0   0   0]\n",
            " [  3   0   4   0   2   0   0   0   0   0   0   0   0   0   0   0   2]\n",
            " [  2   0   0   1   0   7   0   0   0   0   0   1   0   0   0   0   0]\n",
            " [ 12   0   0   0   0   0   8   1   0   1   0   1   0   0   0   0   0]\n",
            " [ 11   0   0   0   0   0   1  14   0   1   1   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0  26   0   0   1   1   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0]\n",
            " [  2   1   0   0   0   0   0   0   0   1   6   0   0   0   0   0   1]\n",
            " [  7   0   0   0   0   0   6   2   1   0   1   5   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2   0   0   1   9   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   1   0   1   1   0  12]\n",
            " [  0   0   0   0   0   0   0   1   0   0   1   0   0   0   9   0   9]\n",
            " [  0   0   1   0   2   0   0   0   0   0   0   0   0   2   5  21  27]\n",
            " [  2   0   0   1   1   2   0   0   0   1   0   0   0   0   2   0  19]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ7YvfVpzll6"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FCdRCoXzll7",
        "outputId": "1b6f808c-1af2-43da-811d-5577729d665e"
      },
      "source": [
        "params = {\n",
        "  'clf__penalty': ['l2'],\n",
        "  'clf__C': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0,1e2,1e4,1e5],\n",
        "  'clf__max_iter': [100,4000,5000],\n",
        "}\n",
        "\n",
        "clf_lr = GridSearchCV(logreg_1, param_grid=params,refit = True,verbose = 1,scoring='f1_weighted')\n",
        "clf_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Score: \", clf_lr.best_score_)\n",
        "print(\"Best Params: \", clf_lr.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 18.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.6530367667820494\n",
            "Best Params:  {'clf__C': 100.0, 'clf__max_iter': 4000, 'clf__penalty': 'l2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk6zexlQzll7",
        "outputId": "967552ee-d245-4991-f865-9d2edb4f7ed8"
      },
      "source": [
        "y_pred = clf_lr.best_estimator_.predict(X_test)\n",
        "#predictions = clf_svc.best_estimator_.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
        "#print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "log_entry = pd.DataFrame([[\"LogisticRegression_best_estimator\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols,index=['LogisticRegression_best_estimator'])\n",
        "log = log.append(log_entry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6625194401244168\n",
            "f1 score 0.6544892649396113\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       308\n",
            "           1       0.56      0.33      0.42        15\n",
            "           2       0.72      0.72      0.72        25\n",
            "           3       0.90      0.64      0.75        14\n",
            "           4       0.43      0.27      0.33        11\n",
            "           5       0.67      0.55      0.60        11\n",
            "           6       0.29      0.35      0.31        23\n",
            "           7       0.39      0.46      0.43        28\n",
            "           8       0.76      0.90      0.83        29\n",
            "           9       0.82      0.75      0.78        12\n",
            "          10       0.55      0.55      0.55        11\n",
            "          11       0.39      0.41      0.40        22\n",
            "          12       0.62      0.67      0.64        12\n",
            "          13       0.18      0.81      0.30        16\n",
            "          14       0.47      0.45      0.46        20\n",
            "          15       1.00      0.34      0.51        58\n",
            "          16       0.73      0.29      0.41        28\n",
            "\n",
            "    accuracy                           0.66       643\n",
            "   macro avg       0.61      0.55      0.54       643\n",
            "weighted avg       0.73      0.66      0.67       643\n",
            "\n",
            "[[256   0   3   0   1   1  15  14   3   1   2   9   2   0   1   0   0]\n",
            " [  1   5   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0]\n",
            " [  2   0  18   0   0   0   1   1   2   0   0   0   1   0   0   0   0]\n",
            " [  1   2   0   9   0   1   0   0   0   0   1   0   0   0   0   0   0]\n",
            " [  3   0   3   0   3   0   0   0   0   0   0   0   0   0   0   0   2]\n",
            " [  4   0   0   0   0   6   0   0   0   0   0   0   0   0   1   0   0]\n",
            " [ 12   0   0   0   0   0   8   0   0   1   0   2   0   0   0   0   0]\n",
            " [ 12   0   0   0   0   0   2  13   0   0   1   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0  26   0   0   1   1   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   1   0   9   0   0   1   0   0   0   0]\n",
            " [  3   1   0   0   0   0   0   0   0   0   6   0   0   1   0   0   0]\n",
            " [  7   0   0   0   0   0   2   3   1   0   0   9   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   2   0   0   1   8   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   1   0  13   1   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   1   0   0   9   9   0   0]\n",
            " [  1   0   1   0   2   0   0   0   0   0   0   0   0  28   5  20   1]\n",
            " [  2   1   0   1   1   1   0   0   0   0   0   0   0  12   2   0   8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "YWlWF2cUzll7",
        "outputId": "6018dc4f-7dd4-4588-9391-12c9a6597857"
      },
      "source": [
        "log.sort_values(by=['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>Classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.623639</td>\n",
              "      <td>0.619163</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression_best_estimator</th>\n",
              "      <td>0.662519</td>\n",
              "      <td>0.654489</td>\n",
              "      <td>LogisticRegression_best_estimator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD_best_estimator</th>\n",
              "      <td>0.654743</td>\n",
              "      <td>0.654686</td>\n",
              "      <td>SGD_best_estimator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.659409</td>\n",
              "      <td>0.659367</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.667185</td>\n",
              "      <td>0.669417</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC_best_estimator</th>\n",
              "      <td>0.667185</td>\n",
              "      <td>0.669417</td>\n",
              "      <td>LinearSVC_best_estimator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.581649</td>\n",
              "      <td>0.713267</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   accuracy  ...                         Classifier\n",
              "SGDClassifier                      0.623639  ...                                NaN\n",
              "LogisticRegression_best_estimator  0.662519  ...  LogisticRegression_best_estimator\n",
              "SGD_best_estimator                 0.654743  ...                 SGD_best_estimator\n",
              "LogisticRegression                 0.659409  ...                                NaN\n",
              "LinearSVC                          0.667185  ...                                NaN\n",
              "LinearSVC_best_estimator           0.667185  ...           LinearSVC_best_estimator\n",
              "MultinomialNB                      0.581649  ...                                NaN\n",
              "\n",
              "[7 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Ep9LIzkPzll7",
        "outputId": "cbd25723-7b18-430f-9670-f31bbffa5f64"
      },
      "source": [
        "log.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fc1fc3f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8ZV3JiHzll7"
      },
      "source": [
        "## Keras implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAp1feq0zll7"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "class FocalLoss(keras.losses.Loss):\n",
        "    def __init__(self, gamma=2., alpha=4.,\n",
        "                 reduction=keras.losses.Reduction.AUTO, name='focal_loss'):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "        \"\"\"\n",
        "        super(FocalLoss, self).__init__(reduction=reduction,\n",
        "                                        name=name)\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(\n",
        "            tf.subtract(1., model_out), self.gamma))\n",
        "        fl = tf.multiply(self.alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return reduced_fl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwRYllyHzll7"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import sklearn.datasets as skds\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "x = df_incidents_l3['token_desc']\n",
        "y = df_incidents_l3['Assignment_group']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.3, random_state=13,stratify=y)\n",
        "\n",
        "num_labels = 22\n",
        "vocab_size = 50000\n",
        "batch_size = 64\n",
        " \n",
        "# define Tokenizer with Vocab Size\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        " \n",
        "x_train = tokenizer.texts_to_matrix(X_train, mode='tfidf')\n",
        "x_test = tokenizer.texts_to_matrix(X_test, mode='tfidf')\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "encoder.fit(y_train)\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "id": "4_nikmRyzll8",
        "outputId": "d71a7b33-98c8-4cb9-9744-caaa799baffd"
      },
      "source": [
        "\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_shape=(vocab_size,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(30))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        " \n",
        "model.compile(loss=FocalLoss(alpha=1),\n",
        "              optimizer='nadam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=30,\n",
        "                    verbose=1,validation_split=0.2,callbacks=[es_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                2500050   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                1530      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 22)                682       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 22)                0         \n",
            "=================================================================\n",
            "Total params: 2,502,262\n",
            "Trainable params: 2,502,262\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-20835e2a50b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     verbose=1,validation_split=0.2,callbacks=[es_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-45-0531a73c92ec>:34 call  *\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1382 convert_to_tensor_v2  **\n        as_ref=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1475 convert_to_tensor\n        (dtype.name, value.dtype.name, value))\n\n    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor 'IteratorGetNext:1' shape=(None, 17) dtype=int64>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_OXgwzAzll8"
      },
      "source": [
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        " \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58_x2nnLzll8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46880c86-3771-4052-ab6f-0e3412693a12"
      },
      "source": [
        "\n",
        "### Save the model\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(clf_lr.best_estimator_, 'model_l3.pkl', compress=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_l3.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_w32XsPzll8"
      },
      "source": [
        "# Finals Conclusions fo Approach2\n",
        "\n",
        "- We first analysed the dataset provided to us, undestood the structure of the data provided - number of columns, field , datatypes etc.\n",
        "- We did Exploratory Data Analysis to derive further insights from this data set and we found that\n",
        "    - Data is very much imbalanced, there are around ~45% of the Groups with less than 20 tickets.\n",
        "    - Few of the tickets are in foreign language like German\n",
        "    - The data has lot of noise in it, for eg- few tickets related to account setup are spread across multiple assignment groups.\n",
        "    \n",
        "- We performed the data cleaning and preprocessing\n",
        "    - Translation: A small number of tickets were written in German. Hence, we used the Google translate python api  to convert German to English to generate the input data for the next steps. However, the google translator rest api can only process a limited number of texts on a daily basis, so we translated the text in batches and saved the file for further processing.\n",
        "    - Make text all lowercase so that the algorithm does not treat the same words in different cases as different\n",
        "    - Removing Noise i.e everything that isnt in a standard number or letter i.e Punctuation, Numerical values\n",
        "    - Removing extract spaces\n",
        "    - Removed punctuations\n",
        "    - Removed words containing numbers\n",
        "    - Stopword Removal: Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words\n",
        "    - Lemmatization\n",
        "    - Tokenization: Tokenization is just the term used to describe the process of converting the normal text strings into a list of tokens i.e words that we actually want. Sentence tokenizer can be used to find the list of sentences and Word tokenizer can be used to find the list of words in strings.\n",
        "    \n",
        "\n",
        "- We then ran a basic benchmarck model using the cleaned and preprocessed dataset\n",
        "    - Since the dataset is very imbalanced, We considered a subset of groups for predictions.  In 74 groups, 46% of tickets belong to group 1 and 16 groups just have more than 100 tickets, rest of the Assignment groups have very less ticket counts which might not add much value to the model prediction. If we conducted random sampling towards all the subcategories, then we would face a problem that we might miss all the tickets in some categories. Hence, we considered the groups that have more than 100 tickets. \n",
        "    - We trained the data using below models:\n",
        "        - Multinomial NB\n",
        "        - Linear Support vector Machine\n",
        "        - Logistic regression\n",
        "        - Xgboost\n",
        "        \n",
        "-  LinearSVC gives better performance with \n",
        "    accuracy 0.833642\n",
        "    f1 score 0.818053\n",
        "\n",
        "<b> Although, it seems like the call is biased towards GRP_0 which has a majority of samples. </b>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Even after downsampling the data we see that the predictions are biased towards GRP_0 which has a majority of samples.\n",
        "- Imbalance causes two problems:\n",
        "    - Training is inefficient as most samples are easy examples that contribute no useful learning signal;\n",
        "    - The easy examples can overwhelm training and lead to degenerate models.\n",
        "    A common solution is to perform some form of hard negative mining that samples hard examples during training or more complex sampling/re weighing schemes.In order to handle the imbalance problem  we used class_weight=balanced hyperparameter while training the model, which tells the model to \"pay more attention\" to samples from an under-represented class.  \n",
        "- Although, the accuracy and f1_score went down. This ensured that the classes were being correctly classified with lesser number of missclassification and good precision/recall scores for all the classes\n",
        "\n",
        "- Next, we used Approach 2 where the ticket would be classified into L1/L2 or L3 classes and then it would be further classified into one of the given assignment groups. \n",
        "\n",
        "- We first created a model to classify the given tickets as l1/l2 or l3 ticket, we found that Linear SVC was giving a better score.\n",
        "- Next, another model was trained considering only l1/l2 level of incidents consisting of GRP_0 and GRP_8.\n",
        "- Finally, a third model was trained considering l3 level of tickets.\n",
        "\n",
        "- We also used hyperparameter tuning, to identify the best classifier with best parameters. We found that LinearSVC was performing the best among all the other classifiers.\n",
        "- We also tried keras implementation with focal loss as a loss function to handle the class imbalance problem, which helps in giving more weightage to groups will less samples, but the results were not satifactory.\n",
        "  \n",
        " - Finally, Logistic Regression gave better performance with hyperparameter tuning and this model would be used for classifying the L3 tickets into one of the groups.\n",
        "    - accuracy 0.706260\n",
        "    - f1 score 0.705392\n",
        "\n",
        "\n",
        "The performance can be further improved by collecting more data for tickets and by running deep learning models like RNN and LSTM's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npBFqqU-XKtb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}